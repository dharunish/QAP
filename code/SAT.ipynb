{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzseUaLL13qB"
   },
   "source": [
    "###Context\n",
    "You are a helpful assistant. You will be given multiple choice answers for each question. Your final answer should be formatted with \"the correct answer is [your choice].\"\n",
    "###Prompts\n",
    "Explain this question in at least 50 words. Then solve for the answer.\n",
    "Explain this problem in at least 50 words. Then solve for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17343,
     "status": "ok",
     "timestamp": 1705337291134,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "vwFYv4VJ2uuo",
    "outputId": "00c2c87a-dc6f-4570-932f-6c52ec18f7a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9825,
     "status": "ok",
     "timestamp": 1705337313716,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "hg0phvniukw0",
    "outputId": "1a45f236-5641-4d30-b204-215db19d1ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "#!pip install transformers\n",
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25845,
     "status": "ok",
     "timestamp": 1705337345464,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "L7iC2yW5wq2P",
    "outputId": "3b68c381-f020-4145-cd51-eca32ae4080d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.2 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "a638272377c84b9aa0d3d490267eb4f6",
      "94fd6d427e3949dab4407f156e69f2dc",
      "68d0a15584464ed4acc51003d8e30e42",
      "046abc9abec940b3a2f56decc0a3dd77",
      "7c82c646d9fa431fbe6577c2af027008",
      "102acad796a94d5c80af2095a859da49",
      "21c64d473e43448c843d07544f3a993c",
      "cfc193ca2d6749acbfe82e9b0d28d709",
      "1449fd6217ec48b0b08f20655f8c00bd",
      "03219f9fed2149429a83877094ae297c",
      "6bae0b432b424a86a1a1a0fc9ea6eb92",
      "526f00e07d9848af80177fc1bf67f76b",
      "ee322482c0c34433b402ed987d9a748a",
      "1b1eb0a852fb410eaa9f662e22a8c5de",
      "87de2fbe485347c9a04809238e1390fe",
      "adc4355915564f0b96620e6e39382eed",
      "601a957778d748dc9028acf6c4708df0",
      "7da5549f294043d19a14189d2cf1c0dd",
      "d4e6e6f274b449358429d18105f3aae3",
      "bf630028295c4fe4844f8ac3a0185b6e",
      "28f63dd553b34950b01a32a2320b1692",
      "7443d7146c414e13aeae371ee1461825",
      "f0c0a446cb45474b965938f354fcf742",
      "fb91f4250aa847ed986ff7f91ba0f992",
      "cf1bc90a91e54ec6bae5540c2b708649",
      "ff055d0f11844756a8118241337571c6",
      "cbb20fa2246c494aae6713908bdb5926",
      "6138a37a0783447ca5b766dbdfe5d48e",
      "31d6100482a24429bd309936fd16ff9b",
      "9399b5b1f75a46c7a8a6a1192587c81a",
      "43b5cd9bca2d41818f217979893b305b",
      "15fe595baa3a4b30a5fb9a8553625e4a",
      "ed21a9d45f2c4a64808b3c8a706fa867"
     ]
    },
    "executionInfo": {
     "elapsed": 7080,
     "status": "ok",
     "timestamp": 1705337356622,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "gzz2V3O-utXD",
    "outputId": "b58e6510-665c-434e-c4cc-cb702d6d4e0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a638272377c84b9aa0d3d490267eb4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526f00e07d9848af80177fc1bf67f76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/57.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c0a446cb45474b965938f354fcf742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "dataset = load_dataset(\"dmayhem93/agieval-sat-math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1705337362765,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "2LxrfOuK96Wo"
   },
   "outputs": [],
   "source": [
    "question = dataset['test'][0]['query'].split('A:')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "error",
     "timestamp": 1705337369879,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "FeeETrY4-mZ4",
    "outputId": "8fe0d87c-db85-467f-8a01-99e8a59e15eb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'our_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2db6346778a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mtrue_answer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"[3]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtrue_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"D\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mour_answer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue_answer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'our_answer' is not defined"
     ]
    }
   ],
   "source": [
    "true_answer = str(dataset['test'][0]['gold'])\n",
    "if true_answer == \"[0]\":\n",
    "  true_answer = \"A\"\n",
    "elif true_answer == \"[1]\":\n",
    "  true_answer = \"B\"\n",
    "elif true_answer == \"[2]\":\n",
    "  true_answer = \"C\"\n",
    "elif true_answer == \"[3]\":\n",
    "  true_answer = \"D\"\n",
    "if our_answer == true_answer:\n",
    "  print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mHmD5U1zDIl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nfyq1FeEzG-c"
   },
   "outputs": [],
   "source": [
    "!pip install flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrEmX3GozHg7"
   },
   "outputs": [],
   "source": [
    "chain_of_thought_aqua = \"\"\"Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
    "will be 21 trees. How many trees did the grove workers plant today?\n",
    "A)6 B)7 C)2 D)4\n",
    "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So,\n",
    "they must have planted 21 - 15 = 6 trees. The correct answer is A.\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A)2 B)4 C)5 D)1\n",
    "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The correct answer is C.\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A)40 B)39 C)20 D)25\n",
    "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74 chocolates.\n",
    "35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The correct answer is B.\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
    "Jason give to Denny?\n",
    "A)18 B)10 C)6 D)8\n",
    "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
    "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The correct answer is D.\n",
    "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
    "have now?\n",
    "A)10 B)3 C)11 D)9\n",
    "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in\n",
    "total he has 7 + 2 = 9 toys. The correct answer is D.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "error",
     "timestamp": 1701564969876,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "8RDwStc73IxQ",
    "outputId": "48d4b032-4ca5-4eda-e314-689bebe00339"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3307350d27a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(dataset[\"test\"]):\n",
    "  print(i)\n",
    "  print(batch['question'])\n",
    "  options = ''\n",
    "  for o in batch['options']:\n",
    "    options = options + \" \" + o\n",
    "  print(options)\n",
    "  print(batch[\"correct\"])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1705337385012,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "6J59Jgakzd96"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "\n",
    "def extract_last_answer(full_text):\n",
    "  try:\n",
    "    segments = full_text.split(\"A: \")\n",
    "    last_answer = segments[-1].strip()\n",
    "    last_answer = last_answer.split(\"Question 1:\")[0].strip()\n",
    "    return last_answer\n",
    "\n",
    "  except ValueError as e:\n",
    "    return None\n",
    "\n",
    "def extract_output_numerical_answer(text, key_phrase=\"The answer is\"): # You may need to create variations of this function to extract your intended numerical answer, depending on the output of your prompt.\n",
    "    if text is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Find the position where 'The answer is' starts in the text\n",
    "        start_pos = text.index(key_phrase) + len(key_phrase)\n",
    "\n",
    "        # Extract the text that comes after 'The answer is'\n",
    "        answer_text = text[start_pos:].strip()\n",
    "\n",
    "        # Use a regular expression to find a floating point or integer number\n",
    "        matches = re.findall(r'[-+]?\\d*\\.\\d+|\\d+', answer_text)\n",
    "\n",
    "        if matches:\n",
    "            return float(matches[0])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKIpJQPlwJRR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_output_numerical_answer(text, key_phrase=\"The answer is\"): # You may need to create variations of this function to extract your intended numerical answer, depending on the output of your prompt.\n",
    "\n",
    "\n",
    "def extract_true_numerical_answer(text):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705337385013,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "Pg0Z8-HCwpVH"
   },
   "outputs": [],
   "source": [
    "key = \"\" #enter your key here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OaQhQ992lA4"
   },
   "source": [
    "#GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412658,
     "status": "ok",
     "timestamp": 1705337943162,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "Wvc0CYjzwuVt",
    "outputId": "bb463b46-46ee-48fd-9f1f-0ea3b0c72540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Correct\n",
      "1 Correct\n",
      "2 Correct\n",
      "3 Correct\n",
      "4 Incorrect\n",
      "5 Correct\n",
      "6 Incorrect\n",
      "7 Incorrect\n",
      "8 Incorrect\n",
      "9 Incorrect\n",
      "10 Incorrect\n",
      "11 Incorrect\n",
      "12 Correct\n",
      "13 Incorrect\n",
      "14 Incorrect\n",
      "15 Incorrect\n",
      "16 Incorrect\n",
      "17 Correct\n",
      "18 Correct\n",
      "19 Correct\n",
      "20 Incorrect\n",
      "21 Incorrect\n",
      "22 Incorrect\n",
      "23 Incorrect\n",
      "24 Correct\n",
      "25 Correct\n",
      "26 Correct\n",
      "27 Incorrect\n",
      "28 Incorrect\n",
      "29 Incorrect\n",
      "30 Incorrect\n",
      "31 Incorrect\n",
      "32 Correct\n",
      "33 Incorrect\n",
      "34 Correct\n",
      "35 Incorrect\n",
      "36 Correct\n",
      "37 Correct\n",
      "38 Incorrect\n",
      "39 Incorrect\n",
      "40 Incorrect\n",
      "41 Incorrect\n",
      "42 Correct\n",
      "43 Correct\n",
      "44 Incorrect\n",
      "45 Incorrect\n",
      "46 Correct\n",
      "47 Incorrect\n",
      "48 Incorrect\n",
      "49 Incorrect\n",
      "50 Correct\n",
      "51 Correct\n",
      "52 Incorrect\n",
      "53 Incorrect\n",
      "54 Incorrect\n",
      "55 Incorrect\n",
      "56 Incorrect\n",
      "57 Incorrect\n",
      "58 Incorrect\n",
      "59 Incorrect\n",
      "60 Incorrect\n",
      "61 Correct\n",
      "62 Incorrect\n",
      "63 Incorrect\n",
      "64 Incorrect\n",
      "65 Incorrect\n",
      "66 Incorrect\n",
      "67 Incorrect\n",
      "68 Correct\n",
      "69 Incorrect\n",
      "70 Incorrect\n",
      "71 Incorrect\n",
      "72 Incorrect\n",
      "73 Correct\n",
      "74 Incorrect\n",
      "75 Incorrect\n",
      "76 Correct\n",
      "77 Correct\n",
      "78 Incorrect\n",
      "79 Correct\n",
      "80 Correct\n",
      "81 Correct\n",
      "82 Correct\n",
      "83 Correct\n",
      "84 Correct\n",
      "85 Correct\n",
      "86 Incorrect\n",
      "87 Incorrect\n",
      "88 Incorrect\n",
      "89 Incorrect\n",
      "90 Incorrect\n",
      "91 Incorrect\n",
      "92 Incorrect\n",
      "93 Incorrect\n",
      "94 Incorrect\n",
      "95 Incorrect\n",
      "96 Correct\n",
      "97 Incorrect\n",
      "98 Correct\n",
      "99 Correct\n",
      "100 Incorrect\n",
      "101 Incorrect\n",
      "102 Incorrect\n",
      "103 Correct\n",
      "104 Incorrect\n",
      "105 Incorrect\n",
      "106 Correct\n",
      "107 Incorrect\n",
      "108 Incorrect\n",
      "109 Incorrect\n",
      "110 Incorrect\n",
      "111 Correct\n",
      "112 Incorrect\n",
      "113 Correct\n",
      "114 Incorrect\n",
      "115 Correct\n",
      "116 Incorrect\n",
      "117 Incorrect\n",
      "118 Incorrect\n",
      "119 Incorrect\n",
      "120 Incorrect\n",
      "121 Incorrect\n",
      "122 Incorrect\n",
      "123 Correct\n",
      "124 Incorrect\n",
      "125 Incorrect\n",
      "126 Correct\n",
      "127 Incorrect\n",
      "128 Incorrect\n",
      "129 Correct\n",
      "130 Incorrect\n",
      "131 Correct\n",
      "132 Incorrect\n",
      "133 Correct\n",
      "134 Correct\n",
      "135 Correct\n",
      "136 Incorrect\n",
      "137 Incorrect\n",
      "138 Correct\n",
      "139 Incorrect\n",
      "140 Incorrect\n",
      "141 Incorrect\n",
      "142 Incorrect\n",
      "143 Incorrect\n",
      "144 Correct\n",
      "145 Incorrect\n",
      "146 Correct\n",
      "147 Incorrect\n",
      "148 Correct\n",
      "149 Correct\n",
      "150 Correct\n",
      "151 Incorrect\n",
      "152 Incorrect\n",
      "153 Incorrect\n",
      "154 Incorrect\n",
      "155 Incorrect\n",
      "156 Incorrect\n",
      "157 Correct\n",
      "158 Correct\n",
      "159 Correct\n",
      "160 Correct\n",
      "161 Incorrect\n",
      "162 Incorrect\n",
      "163 Correct\n",
      "164 Correct\n",
      "165 Correct\n",
      "166 Incorrect\n",
      "167 Incorrect\n",
      "168 Incorrect\n",
      "169 Correct\n",
      "170 Incorrect\n",
      "171 Incorrect\n",
      "172 Incorrect\n",
      "173 Correct\n",
      "174 Incorrect\n",
      "175 Incorrect\n",
      "176 Correct\n",
      "177 Correct\n",
      "178 Incorrect\n",
      "179 Correct\n",
      "180 Incorrect\n",
      "181 Incorrect\n",
      "182 Incorrect\n",
      "183 Correct\n",
      "184 Correct\n",
      "185 Incorrect\n",
      "186 Incorrect\n",
      "187 Correct\n",
      "188 Incorrect\n",
      "189 Incorrect\n",
      "190 Incorrect\n",
      "191 Correct\n",
      "192 Correct\n",
      "193 Correct\n",
      "194 Incorrect\n",
      "195 Correct\n",
      "196 Incorrect\n",
      "197 Incorrect\n",
      "198 Incorrect\n",
      "199 Incorrect\n",
      "200 Correct\n",
      "201 Incorrect\n",
      "202 Incorrect\n",
      "203 Incorrect\n",
      "204 Incorrect\n",
      "205 Correct\n",
      "206 Incorrect\n",
      "207 Incorrect\n",
      "208 Incorrect\n",
      "209 Correct\n",
      "210 Correct\n",
      "211 Incorrect\n",
      "212 Incorrect\n",
      "213 Correct\n",
      "214 Correct\n",
      "215 Incorrect\n",
      "216 Incorrect\n",
      "217 Correct\n",
      "218 Incorrect\n",
      "219 Incorrect\n",
      "36.5296803652968\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import time\n",
    "\n",
    "client = OpenAI(api_key=key)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "\n",
    "s,e = 0,len(dataset[\"test\"]) - 1\n",
    "\n",
    "with (open(\"/content/drive/MyDrive/Full_SAT_Log/GPT3.5_Turbo/new_QAP25_Result.txt\", \"w\") as f,\n",
    "    open(\"/content/drive/MyDrive/Full_SAT_Log/GPT3.5_Turbo/new_QAP25_Answer.txt\", \"w\") as d):\n",
    "\n",
    "  f.write(\"new QAP25.: \\n\")\n",
    "  d.write(\"new QAP25.: \\n\")\n",
    "  for i, batch in enumerate(dataset[\"test\"]): # Change debug_dataloader to train_dataloader or dev_dataloader when necessary\n",
    "    if i < s:\n",
    "      continue\n",
    "    if(i > e):\n",
    "      break\n",
    "    question = batch['query'].split('A:')[0]\n",
    "    #prompt = f\"{question} Take a deep breath and work on this problem step-by-step.\"\n",
    "    prompt = f\"{question} Explain this problem to me in at least 25 words. Then solve for the answer.\"\n",
    "    #prompt = f\"{question}\"\n",
    "    #prompt = f\"{chain_of_thought_aqua}\\n{question}\"\n",
    "    #prompt = f\"{question} Let's first understand the problem, extract relevant variables and their corresponding numerals, \" \\\n",
    "    #         \"and devise a complete plan. Then, let's carry out the plan, calculate intermediate variables \" \\\n",
    "    #         \"(pay attention to correct numerical calculation and commonsense), \" \\\n",
    "    #         \"solve the problem step by step, and show the answer.\"\n",
    "    true_answer = str(batch['gold'])\n",
    "    if true_answer == \"[0]\":\n",
    "      true_answer = \"A\"\n",
    "    elif true_answer == \"[1]\":\n",
    "      true_answer = \"B\"\n",
    "    elif true_answer == \"[2]\":\n",
    "      true_answer = \"C\"\n",
    "    elif true_answer == \"[3]\":\n",
    "      true_answer = \"D\"\n",
    "    response = client.chat.completions.create(\n",
    "    model= \"gpt-3.5-turbo\", # \"gpt-4-1106-preview\"\n",
    "    temperature = 0,\n",
    "    seed=42,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant. You will be given multiple choice answers for each question. Your final answer should be formatted with 'the correct answer is [your choice].'\"},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "             ]\n",
    "    )\n",
    "    answer_line = response.choices[0].message.content\n",
    "    our_answer = re.findall(\"the correct answer is \\(*([A|B|C|D])\\)*\", answer_line,re.IGNORECASE)\n",
    "    if our_answer == []:\n",
    "      our_answer = \"[]\"\n",
    "    else:\n",
    "      our_answer = our_answer[0]\n",
    "    d.write(f\"Question[{i}]:\\n {question}\\n\")\n",
    "    d.write(f\"Correct answer:\\n {true_answer}\\n\")\n",
    "    d.write(f\"Full answer:\\n {answer_line}\\n\")\n",
    "    d.write(f\"Our answer:\\n {our_answer}\\n\")\n",
    "    d.write(\"-\"*100+\"\\n\")\n",
    "    if our_answer and our_answer == true_answer:\n",
    "      correct += 1\n",
    "      f.write(f\"{i} Correct \\n\")\n",
    "      print(f\"{i} Correct\")\n",
    "    else:\n",
    "      f.write(f\"{i} Incorrect \\n\")\n",
    "      print(f\"{i} Incorrect\")\n",
    "    d.flush()\n",
    "    f.flush()\n",
    "    #if (i + 1) % 3 == 0:\n",
    "    #  time.sleep(60)\n",
    "  score = (correct/(i))*100\n",
    "  print(score)\n",
    "  f.write(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUXQrIaGmOpH"
   },
   "source": [
    "#Phi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "error",
     "timestamp": 1702699796144,
     "user": {
      "displayName": "dharunish yugeswardeenoo",
      "userId": "03424753041026644544"
     },
     "user_tz": 300
    },
    "id": "Fk2USrH9mUNJ",
    "outputId": "8f7469ff-bf70-4779-84a0-9849fdd450c2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b23f3223277a>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Score: {score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmy_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b23f3223277a>\u001b[0m in \u001b[0;36mmy_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   with (open(\"/content/drive/MyDrive/Aqua_Log/Phi/TABDPhi_Result.txt\", \"w\") as f,\n\u001b[0m\u001b[1;32m      3\u001b[0m     open(\"/content/drive/MyDrive/Aqua_Log/Phi/TABDPhi_Answer.txt\", \"w\") as d):\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Take a deep breath and work on this problem step-by-step.: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Aqua_Log/Phi/TABDPhi_Result.txt'"
     ]
    }
   ],
   "source": [
    "def my_test():\n",
    "  with (open(\"/content/drive/MyDrive/Aqua_Log/Phi/TABDPhi_Result.txt\", \"w\") as f,\n",
    "    open(\"/content/drive/MyDrive/Aqua_Log/Phi/TABDPhi_Answer.txt\", \"w\") as d):\n",
    "\n",
    "    f.write(\"Take a deep breath and work on this problem step-by-step.: \\n\")\n",
    "    d.write(\"Take a deep breath and work on this problem step-by-step.: \\n\")\n",
    "    s, e = 0, 99\n",
    "    correct = 0\n",
    "    for i, batch in enumerate(train_dataloader): # Change debug_dataloader to train_dataloader or dev_dataloader when necessary\n",
    "      if i < s:\n",
    "        continue\n",
    "      if(i > e):\n",
    "        break\n",
    "      question = batch['question']\n",
    "      options = ''\n",
    "      for o in batch['options']:\n",
    "        options = options + \" \" + o\n",
    "      #prompt = f\"{question} \\n {options} \\n Take a deep breath and work on this problem step-by-step.\"\n",
    "      prompt = f\"{question} \\n {options} \\n Explain this problem to me in at least 200 words. Then solve for the answer.\"\n",
    "      #prompt = f\"{question}\\n{options}\\n\"\n",
    "      #prompt = f\"{question} Explain this problem to me in at least 200 words. Then solve for the answer.\"\n",
    "      #prompt = f\"{question} Take a deep breath and work on this problem step-by-step.\"\n",
    "      #prompt = question\n",
    "      #prompt = question_analysis_prompt_few_shot + \"\\n\" + \"Q: \" + question\n",
    "      #prompt = QAP_COT_Combination + \"\\n\" + \"Q: \" + question\n",
    "      true_answer = batch['correct']\n",
    "      numerical_true_answer = extract_true_numerical_answer(true_answer)\n",
    "      inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "      inputs = inputs.to(\"cuda\")\n",
    "      outputs = model.generate(**inputs, max_new_tokens=350, do_sample=False) # You may need to modify max_new_tokens\n",
    "\n",
    "      answer_line = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "      our_answer = re.findall(\"the correct answer is ([A|B|C|D|E])\", answer_line,re.IGNORECASE)\n",
    "      if our_answer == []:\n",
    "        our_answer = \"[]\"\n",
    "      else:\n",
    "        our_answer = our_answer[0]\n",
    "      d.write(f\"Question[{i}]:\\n {question}\\n\")\n",
    "      d.write(f\"Correct answer:\\n {true_answer}\\n\")\n",
    "      d.write(f\"Full answer:\\n {answer_line}\\n\")\n",
    "      d.write(f\"Our answer:\\n {our_answer}\\n\")\n",
    "      d.write(\"-\"*100+\"\\n\")\n",
    "      if our_answer and our_answer == true_answer:\n",
    "        correct += 1\n",
    "        f.write(f\"{i} Correct \\n\")\n",
    "        print(f\"{i} Correct\")\n",
    "      else:\n",
    "        f.write(f\"{i} Incorrect \\n\")\n",
    "        print(f\"{i} Incorrect\")\n",
    "      d.flush()\n",
    "      f.flush()\n",
    "      if (i + 1) % 3 == 0:\n",
    "        time.sleep(60)\n",
    "    score = (correct/(i))*100\n",
    "    print(score)\n",
    "    f.write(f\"Score: {score}\")\n",
    "my_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pMSPTYfb-lG"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "x = [\"Baseline\", \"QAP50\", \"QAP100\",\"QAP150\", \"TADB\"]\n",
    "\n",
    "y = [52, 54, 56, 61, 44]\n",
    "plt.yticks([i for i in range(0,100,5)])\n",
    "bar_container = plt.bar(x,y)\n",
    "plt.bar_label(bar_container)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orUSEmzYSMsp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with (open(\"/content/drive/MyDrive/GSM8K_Log/GPT3.5_Turbo/QAP200_Answer.txt\", \"r\") as inp):\n",
    "\n",
    "  content = inp.read()\n",
    "  txt = re.findall(\"Full answer:(.*?)Numeric answer:\",content,re.DOTALL)\n",
    "print(len(txt))\n",
    "count = []\n",
    "for t in txt:\n",
    "  count.append(len(t.split()))\n",
    "\n",
    "#print(count)\n",
    "import statistics\n",
    "statistics.mean(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO-z-UawnvRW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmwXAJWnoaDt"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = [i for i in range(len(count))]\n",
    "plt.bar(x,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Knic7GAocqO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03219f9fed2149429a83877094ae297c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "046abc9abec940b3a2f56decc0a3dd77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03219f9fed2149429a83877094ae297c",
      "placeholder": "​",
      "style": "IPY_MODEL_6bae0b432b424a86a1a1a0fc9ea6eb92",
      "value": " 1.83k/1.83k [00:00&lt;00:00, 40.7kB/s]"
     }
    },
    "102acad796a94d5c80af2095a859da49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1449fd6217ec48b0b08f20655f8c00bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15fe595baa3a4b30a5fb9a8553625e4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b1eb0a852fb410eaa9f662e22a8c5de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4e6e6f274b449358429d18105f3aae3",
      "max": 57002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf630028295c4fe4844f8ac3a0185b6e",
      "value": 57002
     }
    },
    "21c64d473e43448c843d07544f3a993c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28f63dd553b34950b01a32a2320b1692": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d6100482a24429bd309936fd16ff9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43b5cd9bca2d41818f217979893b305b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "526f00e07d9848af80177fc1bf67f76b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee322482c0c34433b402ed987d9a748a",
       "IPY_MODEL_1b1eb0a852fb410eaa9f662e22a8c5de",
       "IPY_MODEL_87de2fbe485347c9a04809238e1390fe"
      ],
      "layout": "IPY_MODEL_adc4355915564f0b96620e6e39382eed"
     }
    },
    "601a957778d748dc9028acf6c4708df0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6138a37a0783447ca5b766dbdfe5d48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68d0a15584464ed4acc51003d8e30e42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfc193ca2d6749acbfe82e9b0d28d709",
      "max": 1832,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1449fd6217ec48b0b08f20655f8c00bd",
      "value": 1832
     }
    },
    "6bae0b432b424a86a1a1a0fc9ea6eb92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7443d7146c414e13aeae371ee1461825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c82c646d9fa431fbe6577c2af027008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7da5549f294043d19a14189d2cf1c0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87de2fbe485347c9a04809238e1390fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28f63dd553b34950b01a32a2320b1692",
      "placeholder": "​",
      "style": "IPY_MODEL_7443d7146c414e13aeae371ee1461825",
      "value": " 57.0k/57.0k [00:00&lt;00:00, 161kB/s]"
     }
    },
    "9399b5b1f75a46c7a8a6a1192587c81a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94fd6d427e3949dab4407f156e69f2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_102acad796a94d5c80af2095a859da49",
      "placeholder": "​",
      "style": "IPY_MODEL_21c64d473e43448c843d07544f3a993c",
      "value": "Downloading readme: 100%"
     }
    },
    "a638272377c84b9aa0d3d490267eb4f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94fd6d427e3949dab4407f156e69f2dc",
       "IPY_MODEL_68d0a15584464ed4acc51003d8e30e42",
       "IPY_MODEL_046abc9abec940b3a2f56decc0a3dd77"
      ],
      "layout": "IPY_MODEL_7c82c646d9fa431fbe6577c2af027008"
     }
    },
    "adc4355915564f0b96620e6e39382eed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf630028295c4fe4844f8ac3a0185b6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbb20fa2246c494aae6713908bdb5926": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf1bc90a91e54ec6bae5540c2b708649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9399b5b1f75a46c7a8a6a1192587c81a",
      "max": 220,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43b5cd9bca2d41818f217979893b305b",
      "value": 220
     }
    },
    "cfc193ca2d6749acbfe82e9b0d28d709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4e6e6f274b449358429d18105f3aae3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed21a9d45f2c4a64808b3c8a706fa867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee322482c0c34433b402ed987d9a748a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_601a957778d748dc9028acf6c4708df0",
      "placeholder": "​",
      "style": "IPY_MODEL_7da5549f294043d19a14189d2cf1c0dd",
      "value": "Downloading data: 100%"
     }
    },
    "f0c0a446cb45474b965938f354fcf742": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb91f4250aa847ed986ff7f91ba0f992",
       "IPY_MODEL_cf1bc90a91e54ec6bae5540c2b708649",
       "IPY_MODEL_ff055d0f11844756a8118241337571c6"
      ],
      "layout": "IPY_MODEL_cbb20fa2246c494aae6713908bdb5926"
     }
    },
    "fb91f4250aa847ed986ff7f91ba0f992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6138a37a0783447ca5b766dbdfe5d48e",
      "placeholder": "​",
      "style": "IPY_MODEL_31d6100482a24429bd309936fd16ff9b",
      "value": "Generating test split: 100%"
     }
    },
    "ff055d0f11844756a8118241337571c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15fe595baa3a4b30a5fb9a8553625e4a",
      "placeholder": "​",
      "style": "IPY_MODEL_ed21a9d45f2c4a64808b3c8a706fa867",
      "value": " 220/220 [00:00&lt;00:00, 2476.81 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
